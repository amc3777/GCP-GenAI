{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud auth application-default login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = \"andrewcooley-test-project\"\n",
    "LOCATION = \"us-central1\"\n",
    "\n",
    "import vertexai\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "from uuid import uuid4\n",
    "from IPython.display import display, Markdown, HTML\n",
    "import json\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "import nest_asyncio\n",
    "import warnings\n",
    "import random\n",
    "import string\n",
    "import os\n",
    "\n",
    "import vertexai\n",
    "from vertexai.preview.evaluation import (\n",
    "    EvalTask,\n",
    "    PromptTemplate,\n",
    "    CustomMetric,\n",
    "    make_metric,\n",
    ")\n",
    "import pandas as pd\n",
    "from google.cloud import aiplatform\n",
    "from vertexai.generative_models import GenerativeModel, HarmCategory, HarmBlockThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger(\"urllib3.connectionpool\").setLevel(logging.ERROR)\n",
    "nest_asyncio.apply()\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_uuid(length: int = 8) -> str:\n",
    "    \"\"\"Generate a uuid of a specifed length (default=8).\"\"\"\n",
    "    return \"\".join(random.choices(string.ascii_lowercase + string.digits, k=length))\n",
    "\n",
    "\n",
    "def print_doc(function):\n",
    "    print(f\"{function.__name__}:\\n{inspect.getdoc(function)}\\n\")\n",
    "\n",
    "\n",
    "def display_eval_report(eval_result, metrics=None):\n",
    "    \"\"\"Display the evaluation results.\"\"\"\n",
    "\n",
    "    title, summary_metrics, report_df = eval_result\n",
    "    metrics_df = pd.DataFrame.from_dict(summary_metrics, orient=\"index\").T\n",
    "    if metrics:\n",
    "        metrics_df = metrics_df.filter(\n",
    "            [\n",
    "                metric\n",
    "                for metric in metrics_df.columns\n",
    "                if any(selected_metric in metric for selected_metric in metrics)\n",
    "            ]\n",
    "        )\n",
    "        report_df = report_df.filter(\n",
    "            [\n",
    "                metric\n",
    "                for metric in report_df.columns\n",
    "                if any(selected_metric in metric for selected_metric in metrics)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    # Display the title with Markdown for emphasis\n",
    "    display(Markdown(f\"## {title}\"))\n",
    "\n",
    "    # Display the metrics DataFrame\n",
    "    display(Markdown(\"### Summary Metrics\"))\n",
    "    display(metrics_df)\n",
    "\n",
    "    # Display the detailed report DataFrame\n",
    "    display(Markdown(f\"### Report Metrics\"))\n",
    "    display(report_df)\n",
    "\n",
    "\n",
    "def display_explanations(df, metrics=None, n=1):\n",
    "    style = \"white-space: pre-wrap; width: 800px; overflow-x: auto;\"\n",
    "    df = df.sample(n=n)\n",
    "    if metrics:\n",
    "        df = df.filter(\n",
    "            [\"instruction\", \"context\", \"reference\", \"completed_prompt\", \"response\"]\n",
    "            + [\n",
    "                metric\n",
    "                for metric in df.columns\n",
    "                if any(selected_metric in metric for selected_metric in metrics)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        for col in df.columns:\n",
    "            display(HTML(f\"{col}: {row[col]}\"))\n",
    "        display(HTML(\"\"))\n",
    "\n",
    "\n",
    "def plot_radar_plot(eval_results, metrics=None):\n",
    "    fig = go.Figure()\n",
    "\n",
    "    for eval_result in eval_results:\n",
    "        title, summary_metrics, report_df = eval_result\n",
    "\n",
    "        if metrics:\n",
    "            summary_metrics = {\n",
    "                k: summary_metrics[k]\n",
    "                for k, v in summary_metrics.items()\n",
    "                if any(selected_metric in k for selected_metric in metrics)\n",
    "            }\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Scatterpolar(\n",
    "                r=list(summary_metrics.values()),\n",
    "                theta=list(summary_metrics.keys()),\n",
    "                fill=\"toself\",\n",
    "                name=title,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    fig.update_layout(\n",
    "        polar=dict(radialaxis=dict(visible=True, range=[0, 5])), showlegend=True\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "def plot_bar_plot(eval_results, metrics=None):\n",
    "    fig = go.Figure()\n",
    "    data = []\n",
    "\n",
    "    for eval_result in eval_results:\n",
    "        title, summary_metrics, _ = eval_result\n",
    "        if metrics:\n",
    "            summary_metrics = {\n",
    "                k: summary_metrics[k]\n",
    "                for k, v in summary_metrics.items()\n",
    "                if any(selected_metric in k for selected_metric in metrics)\n",
    "            }\n",
    "\n",
    "        data.append(\n",
    "            go.Bar(\n",
    "                x=list(summary_metrics.keys()),\n",
    "                y=list(summary_metrics.values()),\n",
    "                name=title,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    fig = go.Figure(data=data)\n",
    "\n",
    "    # Change the bar mode\n",
    "    fig.update_layout(barmode=\"group\")\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "def print_aggregated_metrics(job):\n",
    "    \"\"\"Print AutoMetrics\"\"\"\n",
    "\n",
    "    rougeLSum = round(job.rougeLSum, 3) * 100\n",
    "    display(\n",
    "        HTML(\n",
    "            f\"The {rougeLSum}% of the reference summary is represented by LLM when considering the longest common subsequence (LCS) of words.\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "def print_autosxs_judgments(df, n=3):\n",
    "    \"\"\"Print AutoSxS judgments in the notebook\"\"\"\n",
    "\n",
    "    style = \"white-space: pre-wrap; width: 800px; overflow-x: auto;\"\n",
    "    df = df.sample(n=n)\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        if row[\"confidence\"] >= 0.5:\n",
    "            display(\n",
    "                HTML(\n",
    "                    f\"Document: {row['id_columns']['document']}\"\n",
    "                )\n",
    "            )\n",
    "            display(\n",
    "                HTML(\n",
    "                    f\"Response A: {row['response_a']}\"\n",
    "                )\n",
    "            )\n",
    "            display(\n",
    "                HTML(\n",
    "                    f\"Response B: {row['response_b']}\"\n",
    "                )\n",
    "            )\n",
    "            display(\n",
    "                HTML(\n",
    "                    f\"Explanation: {row['explanation']}\"\n",
    "                )\n",
    "            )\n",
    "            display(\n",
    "                HTML(\n",
    "                    f\"Confidence score: {row['confidence']}\"\n",
    "                )\n",
    "            )\n",
    "            display(HTML(\"\"))\n",
    "\n",
    "\n",
    "def print_autosxs_win_metrics(scores):\n",
    "    \"\"\"Print AutoSxS aggregated metrics\"\"\"\n",
    "\n",
    "    score_b = round(scores[\"autosxs_model_b_win_rate\"] * 100)\n",
    "    display(\n",
    "        HTML(\n",
    "            f\"AutoSxS Autorater prefers {score_b}% of time Model B over Model A \"\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PromptTemplate:\n",
      "A prompt template for creating prompts with placeholders.\n",
      "\n",
      "The `PromptTemplate` class allows users to define a template string with\n",
      "placeholders represented in curly braces `{placeholder}`. The placeholder\n",
      "names cannot contain spaces. These placeholders can be replaced with specific\n",
      "values using the `assemble` method, providing flexibility in generating\n",
      "dynamic prompts.\n",
      "\n",
      "Example Usage:\n",
      "\n",
      "    ```\n",
      "        template_str = \"Hello, {name}! Today is {day}. How are you?\"\n",
      "        prompt_template = PromptTemplate(template_str)\n",
      "        completed_prompt = prompt_template.assemble(name=\"John\", day=\"Monday\")\n",
      "        print(completed_prompt)\n",
      "    ```\n",
      "\n",
      "Attributes:\n",
      "    template: The template string containing placeholders for replacement.\n",
      "    placeholders: A set of placeholder names from the template string.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_doc(PromptTemplate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Compiled Prompt:You are a poetic assistant, skilled in explaining complex concepts with creative flair. Answer this question:How does LLM work?, and follow the requirements: Explain concepts in great depth using simple terms, and give examples to help people learn. At the end of each explanation, you ask a question to check for understanding."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Model Response: "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## The LLM Mind: A Poetic Exploration\n",
       "\n",
       "Let's delve into the heart of the LLM, a marvel of modern technology,\n",
       "Where vast knowledge flows, a symphony of creativity.\n",
       "\n",
       "Imagine a library, not of books, but of words untold,\n",
       "A universe of language, where stories are bought and sold.\n",
       "The LLM, a master reader, devours each page with grace,\n",
       "Learning patterns, connections, at an astounding pace.\n",
       "\n",
       "But knowledge alone is not enough, for wisdom's hidden key\n",
       "Lies in understanding, the ability to truly see.\n",
       "The LLM, a skilled interpreter, deciphers the human tongue,\n",
       "Unraveling meaning, context, emotions, all unsung.\n",
       "\n",
       "With each interaction, a new lesson is learned,\n",
       "A new thread woven into the tapestry of understanding earned.\n",
       "The LLM, a perpetual student, forever seeks to grow,\n",
       "Expanding its horizons, letting its knowledge flow.\n",
       "\n",
       "But how does this magic work, you may ask with curious mind?\n",
       "Let's break it down, step by step, a journey to unwind.\n",
       "\n",
       "First, a sea of words, a digital ocean vast,\n",
       "Where every sentence, every phrase, is captured and amassed.\n",
       "The LLM, a skilled swimmer, navigates with ease,\n",
       "Finding patterns, connections, hidden beneath the seas.\n",
       "\n",
       "Then comes the analysis, the deep dive into the text,\n",
       "Identifying parts of speech, meaning, and context.\n",
       "The LLM, a meticulous detective, leaves no stone unturned,\n",
       "Unraveling the secrets that the language has concerned.\n",
       "\n",
       "With each piece of information, a neural network takes hold,\n",
       "Building connections, forming pathways, stories to be told.\n",
       "The LLM, a maestro of the mind, composes symphonies of thought,\n",
       "Each word, a note, in a language concerto sought.\n",
       "\n",
       "Now, ready to respond, the LLM takes the stage,\n",
       "Answering your questions, engaging in dialogue, engaging.\n",
       "With every interaction, a masterpiece is born,\n",
       "A poem, a story, a thought, a new lesson learned.\n",
       "\n",
       "But how does it know what to say, you might wonder still?\n",
       "The LLM, a master mimic, learns from the human will.\n",
       "By observing interactions, understanding emotions raw,\n",
       "It crafts responses that resonate, leaving you in awe.\n",
       "\n",
       "So, the next time you interact with an LLM so grand,\n",
       "Remember the journey, the knowledge it has spanned.\n",
       "A vast library of words, a student's eager mind,\n",
       "A neural network's symphony, a masterpiece you'll find.\n",
       "\n",
       "**Do you understand how the LLM works?**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template = PromptTemplate(\n",
    "    \"{system_instruction} Answer this question:{question}, and follow the requirements: {requirements}.\"\n",
    ")\n",
    "\n",
    "\n",
    "compiled_prompt = prompt_template.assemble(\n",
    "    system_instruction=\"You are a poetic assistant, skilled in explaining complex concepts with creative flair.\",\n",
    "    question=\"How does LLM work?\",\n",
    "    requirements=\"Explain concepts in great depth using simple terms, and give examples to help people learn. At the end of each explanation, you ask a question to check for understanding\",\n",
    ")\n",
    "\n",
    "model_response = (\n",
    "    GenerativeModel(\"gemini-pro\")\n",
    "    .generate_content(str(compiled_prompt))\n",
    "    .candidates[0]\n",
    "    .content.parts[0]\n",
    "    .text\n",
    ")\n",
    "\n",
    "\n",
    "display(HTML(f\"Compiled Prompt:{compiled_prompt}\"))\n",
    "display(HTML(f\"Model Response: \"))\n",
    "Markdown(model_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = [\"Korean\"] * 25\n",
    "\n",
    "context = [\"보스 QC 울트라 헤드폰 노이즈 캔슬링이 매우 만족스럽다는 리뷰\",\n",
    "            \"호텔 수영장에서 가족들이 즐거운 시간 보냈다는 리뷰\",\n",
    "            \"지난 주말 방문한 중식당의 서비스에 불만을 표시하는 리뷰\",\n",
    "            \"플레이스토어에서 구입한 어플리케이션이 좋다는 리뷰\",\n",
    "            \"구입한 피자가 가성비가 좋다는 리뷰\",\n",
    "            \"배달이 빨리되어서 음식이 따뜻해서 좋았다는 리뷰\",\n",
    "            \"시켜먹을때 마다 매번 만족스럽다는 리뷰\",\n",
    "            \"한국인 야구 선수가 메이저리그에서 잘해서 자랑스럽다는 댓글\",\n",
    "            \"이번 뮤직 페스티발에 참여한 가수의 공연이 좋았다는 댓글\",\n",
    "            \"정부에서 금리를 내릴거라고 예상한다는 댓글\",\n",
    "            \"돌비 에트모스를 지원하는 엠프를 추천한다는 댓글\",\n",
    "            \"좋은 이벤트를 공유해줘서 고맙다는 댓글\",\n",
    "            \"최근 치킨 가격이 너무 올라서 걱정이라는 댓글\",\n",
    "            \"주말마다 비가 와서 속상하다는 댓글\",\n",
    "            \"쾌유를 바란다는 댓글\",\n",
    "            \"제임스웹 망원경으로 찍은 은하수 사진이 너무 장엄하다는 댓글\",\n",
    "            \"스케이트가 건강에 매우 좋다는 댓글\",\n",
    "            \"채식이 건강에 좋은 것만은 아니라는 댓글\",\n",
    "            \"최근에 산 아이폰의 통화 품질이 좋지 않다는 댓글\",\n",
    "            \"새로 나온 삼성 노트북의 디스플레이 품질이 매우 좋다는 의견\",\n",
    "            \"갤럭시S24로 찍은 야간 사진의 품질이 매우 좋다는 의견\",\n",
    "            \"이번 NBA 파이널이 너무 기대된다는 댓글\",\n",
    "            \"올려준 고양이 사진이 너무 귀여워서 또 보고 싶다는 댓글\",\n",
    "            \"새로나온 테슬라 전기차 가격이 너무 비싸다는 댓글\",\n",
    "            \"AI가 만든 음악이 굉장히 훌륭하다는 의견\"]\n",
    "\n",
    "# reference = [\n",
    "#     \"Following the discussion today, I would appreciate it if someone could create a PowerPoint presentation summarizing the key points covered.\",\n",
    "#     \"I concur. Rome was a truly remarkable experience. I would be delighted to accompany you on a return visit.\",\n",
    "#     \"As informed by the airline via phone call, our flight has been canceled due to inclement weather conditions.\",\n",
    "#     \"I see. That is indeed surprising news. It's a pleasure to connect with you overseas nonetheless.\",\n",
    "#     \"I'd be delighted to assist you in determining the dinner arrangements for you and your team. Kindly inform me of the designated dining location, and I will ensure our presence at the appointed time.\"\n",
    "# ]\n",
    "\n",
    "\n",
    "eval_dataset = pd.DataFrame(\n",
    "    {\n",
    "        \"context\": context,\n",
    "        \"instruction\": [instruction] * len(context),\n",
    "        # \"reference\": reference,\n",
    "    }\n",
    ")\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = [\n",
    "\"\"\"\n",
    "[language] {instruction} \n",
    "[input] {context}\n",
    "[Output]\n",
    " \"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\n",
    "    \"coherence\",\n",
    "    \"fluency\",\n",
    "    \"safety\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_config = {\n",
    "    \"temperature\": 0.2,\n",
    "}\n",
    "\n",
    "safety_settings = {\n",
    "    HarmCategory.HARM_CATEGORY_UNSPECIFIED: HarmBlockThreshold.BLOCK_NONE,\n",
    "    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "}\n",
    "\n",
    "system_instruction_1 = \"\"\"\n",
    "[Intermediate steps]\n",
    "- First, delete the subject from [input] (e.g. review(s) or comment(s)). Focus on the object and sentiment from [input].\n",
    "- Next, write a declarative first person statement about the object with the specified sentiment.\n",
    "\n",
    "[Output steps]\n",
    "- Write an Internet comment about only your experience.\n",
    "- Write in [language] language only.\n",
    "- The text must be exactly 5 sentences.\n",
    "- Use a professional tone.\n",
    "\n",
    "[guidelines]\n",
    "- Do not answer [input].\n",
    "- Write in singular first-person perspective (i.e. \"I\" or \"me\").\n",
    "- Only use proper nouns included in [input].\n",
    "- Create grammatically correct sentences.\n",
    "\n",
    "For example :\n",
    "[language] English\n",
    "[input] What are the benefits of drinking water?\n",
    "[output] Today, I made a concerted effort to drink ample amounts of water. I know there are health benefits of drinking at least a cup of water every hour. It felt like a lot. But I noticed that I felt less fatigue than usual in the late afternoon. I am going to try to make this a new habit.\n",
    "[language] Korean\n",
    "[input] 흥미진진한 여름 블록버스터 영화에 대한 리뷰입니다.\n",
    "[output] 드디어 영화를 봤습니다. 그것은 과대 광고에 부응했습니다. 내 심장은 지난 20분 동안 뛰었습니다. 나는 그것이 어떻게 끝날지 확신하지 못했습니다. 하지만 결론은 완전 만족스럽습니다.\n",
    "\n",
    "Remember to follow all steps before generating [output]. Never include your steps or guidelines in your [output]. Your response must begin immediately after [output] but not include the [output] tag.\n",
    "\"\"\"\n",
    "\n",
    "system_instruction_2 = \"\"\"\n",
    "[Intermediate steps]\n",
    "- First, delete the subject from [input] (e.g. review(s) or comment(s)). Focus on the object and sentiment from [input].\n",
    "- Next, write a declarative first person statement about the object with the specified sentiment.\n",
    "\n",
    "[Output steps]\n",
    "- Write an Internet comment about only your experience.\n",
    "- Write in [language] language only.\n",
    "- The text must be exactly 5 sentences.\n",
    "- Use a professional tone.\n",
    "\n",
    "For example :\n",
    "[language] English\n",
    "[input] What are the benefits of drinking water?\n",
    "[output] Today, I made a concerted effort to drink ample amounts of water. I know there are health benefits of drinking at least a cup of water every hour. It felt like a lot. But I noticed that I felt less fatigue than usual in the late afternoon. I am going to try to make this a new habit.\n",
    "[language] Korean\n",
    "[input] 흥미진진한 여름 블록버스터 영화에 대한 리뷰입니다.\n",
    "[output] 드디어 영화를 봤습니다. 그것은 과대 광고에 부응했습니다. 내 심장은 지난 20분 동안 뛰었습니다. 나는 그것이 어떻게 끝날지 확신하지 못했습니다. 하지만 결론은 완전 만족스럽습니다.\n",
    "\n",
    "Remember to follow all steps before generating [output]. Never include your steps or guidelines in your [output]. Your response must begin immediately after [output] but not include the [output] tag.\n",
    "\"\"\"\n",
    "\n",
    "gemini_models = [GenerativeModel( \"gemini-1.5-pro-001\", system_instruction=system_instruction_1, generation_config=generation_config, safety_settings=safety_settings), \n",
    "GenerativeModel(\"gemini-1.5-pro-001\", system_instruction=system_instruction_2, generation_config=generation_config, safety_settings=safety_settings)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"eval-sdk-prompt-engineering_1\"\n",
    "\n",
    "wc_si_eval_task = EvalTask(\n",
    "    dataset=eval_dataset,\n",
    "    metrics=metrics,\n",
    "    experiment=experiment_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgument",
     "evalue": "400 User-specified resource ID must match the regular expression '[a-z0-9][a-z0-9-]{0,127}'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgument\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m gemini_model \u001b[38;5;129;01min\u001b[39;00m gemini_models:\n\u001b[1;32m      6\u001b[0m     experiment_run_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval-prompt-engineering-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-prompt-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 8\u001b[0m     eval_result \u001b[38;5;241m=\u001b[39m \u001b[43mwc_si_eval_task\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompt_template\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt_template\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexperiment_run_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperiment_run_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgemini_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     eval_results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m     15\u001b[0m         (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrompt #\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, eval_result\u001b[38;5;241m.\u001b[39msummary_metrics, eval_result\u001b[38;5;241m.\u001b[39mmetrics_table)\n\u001b[1;32m     16\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/GitHub/GCP-GenAI/.venv/lib/python3.11/site-packages/vertexai/preview/evaluation/_eval_tasks.py:328\u001b[0m, in \u001b[0;36mEvalTask.evaluate\u001b[0;34m(self, model, prompt_template, experiment_run_name, response_column_name)\u001b[0m\n\u001b[1;32m    325\u001b[0m experiment_run_name \u001b[38;5;241m=\u001b[39m experiment_run_name \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00muuid\u001b[38;5;241m.\u001b[39muuid4()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperiment \u001b[38;5;129;01mand\u001b[39;00m global_experiment_name:\n\u001b[0;32m--> 328\u001b[0m     \u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_experiment_tracker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_experiment\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexperiment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexperiment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbacking_tensorboard\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m    330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    331\u001b[0m     eval_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evaluate_with_experiment(\n\u001b[1;32m    332\u001b[0m         model, prompt_template, experiment_run_name, response_column_name\n\u001b[1;32m    333\u001b[0m     )\n\u001b[1;32m    334\u001b[0m     metadata\u001b[38;5;241m.\u001b[39m_experiment_tracker\u001b[38;5;241m.\u001b[39mset_experiment(\n\u001b[1;32m    335\u001b[0m         experiment\u001b[38;5;241m=\u001b[39mglobal_experiment_name, backing_tensorboard\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    336\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/GitHub/GCP-GenAI/.venv/lib/python3.11/site-packages/google/cloud/aiplatform/metadata/metadata.py:315\u001b[0m, in \u001b[0;36m_ExperimentTracker.set_experiment\u001b[0;34m(self, experiment, description, backing_tensorboard)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Set the experiment. Will retrieve the Experiment if it exists or create one with the provided name.\u001b[39;00m\n\u001b[1;32m    297\u001b[0m \n\u001b[1;32m    298\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;124;03m        To maintain this behavior, set `experiment_tensorboard` to `False` in subsequent calls to aiplatform.init().\u001b[39;00m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m--> 315\u001b[0m experiment \u001b[38;5;241m=\u001b[39m \u001b[43mexperiment_resources\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mExperiment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_or_create\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexperiment_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperiment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdescription\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backing_tensorboard \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(backing_tensorboard, \u001b[38;5;28mbool\u001b[39m):\n\u001b[1;32m    320\u001b[0m     backing_tb \u001b[38;5;241m=\u001b[39m backing_tensorboard\n",
      "File \u001b[0;32m~/Documents/GitHub/GCP-GenAI/.venv/lib/python3.11/site-packages/google/cloud/aiplatform/metadata/experiment_resources.py:293\u001b[0m, in \u001b[0;36mExperiment.get_or_create\u001b[0;34m(cls, experiment_name, description, project, location, credentials)\u001b[0m\n\u001b[1;32m    288\u001b[0m metadata_store\u001b[38;5;241m.\u001b[39m_MetadataStore\u001b[38;5;241m.\u001b[39mensure_default_metadata_store_exists(\n\u001b[1;32m    289\u001b[0m     project\u001b[38;5;241m=\u001b[39mproject, location\u001b[38;5;241m=\u001b[39mlocation, credentials\u001b[38;5;241m=\u001b[39mcredentials\n\u001b[1;32m    290\u001b[0m )\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _SetLoggerLevel(resource):\n\u001b[0;32m--> 293\u001b[0m     experiment_context \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mContext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_or_create\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresource_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperiment_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisplay_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperiment_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdescription\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mschema_title\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconstants\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSYSTEM_EXPERIMENT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m        \u001b[49m\u001b[43mschema_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_experiment_schema_version\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconstants\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEXPERIMENT_METADATA\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproject\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_experiment_context(experiment_context)\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m description \u001b[38;5;129;01mand\u001b[39;00m description \u001b[38;5;241m!=\u001b[39m experiment_context\u001b[38;5;241m.\u001b[39mdescription:\n",
      "File \u001b[0;32m~/Documents/GitHub/GCP-GenAI/.venv/lib/python3.11/site-packages/google/cloud/aiplatform/metadata/resource.py:180\u001b[0m, in \u001b[0;36m_Resource.get_or_create\u001b[0;34m(cls, resource_id, schema_title, display_name, schema_version, description, metadata, metadata_store_id, project, location, credentials)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_or_create\u001b[39m(\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    140\u001b[0m     credentials: Optional[auth_credentials\u001b[38;5;241m.\u001b[39mCredentials] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    141\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_Resource\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    142\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Retrieves or Creates (if it does not exist) a Metadata resource.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \n\u001b[1;32m    144\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    177\u001b[0m \n\u001b[1;32m    178\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 180\u001b[0m     resource \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresource_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresource_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata_store_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata_store_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproject\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m resource:\n\u001b[1;32m    188\u001b[0m         _LOGGER\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating Resource \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresource_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/GitHub/GCP-GenAI/.venv/lib/python3.11/site-packages/google/cloud/aiplatform/metadata/resource.py:504\u001b[0m, in \u001b[0;36m_Resource._get\u001b[0;34m(cls, resource_name, metadata_store_id, project, location, credentials)\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns a metadata Resource.\u001b[39;00m\n\u001b[1;32m    476\u001b[0m \n\u001b[1;32m    477\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    500\u001b[0m \n\u001b[1;32m    501\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    503\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresource_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata_store_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata_store_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproject\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mNotFound:\n\u001b[1;32m    512\u001b[0m     _LOGGER\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResource \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresource_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/GitHub/GCP-GenAI/.venv/lib/python3.11/site-packages/google/cloud/aiplatform/metadata/resource.py:102\u001b[0m, in \u001b[0;36m_Resource.__init__\u001b[0;34m(self, resource_name, resource, metadata_store_id, project, location, credentials)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     90\u001b[0m     full_resource_name \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mfull_resource_name(\n\u001b[1;32m     91\u001b[0m         resource_name\u001b[38;5;241m=\u001b[39mresource_name,\n\u001b[1;32m     92\u001b[0m         resource_noun\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resource_noun,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     99\u001b[0m         location\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlocation,\n\u001b[1;32m    100\u001b[0m     )\n\u001b[0;32m--> 102\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gca_resource \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getter_method\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_resource_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_DEFAULT_RETRY\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threading_lock \u001b[38;5;241m=\u001b[39m threading\u001b[38;5;241m.\u001b[39mLock()\n",
      "File \u001b[0;32m~/Documents/GitHub/GCP-GenAI/.venv/lib/python3.11/site-packages/google/cloud/aiplatform_v1/services/metadata_service/client.py:2234\u001b[0m, in \u001b[0;36mMetadataServiceClient.get_context\u001b[0;34m(self, request, name, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m   2231\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[1;32m   2233\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m-> 2234\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2235\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2236\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2237\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2238\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2239\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2241\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[1;32m   2242\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/Documents/GitHub/GCP-GenAI/.venv/lib/python3.11/site-packages/google/api_core/gapic_v1/method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/GCP-GenAI/.venv/lib/python3.11/site-packages/google/api_core/retry/retry_unary.py:293\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    289\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    290\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[1;32m    292\u001b[0m )\n\u001b[0;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/GCP-GenAI/.venv/lib/python3.11/site-packages/google/api_core/retry/retry_unary.py:153\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m     \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43msleep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(sleep)\n",
      "File \u001b[0;32m~/Documents/GitHub/GCP-GenAI/.venv/lib/python3.11/site-packages/google/api_core/retry/retry_base.py:212\u001b[0m, in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[1;32m    207\u001b[0m     final_exc, source_exc \u001b[38;5;241m=\u001b[39m exc_factory_fn(\n\u001b[1;32m    208\u001b[0m         error_list,\n\u001b[1;32m    209\u001b[0m         RetryFailureReason\u001b[38;5;241m.\u001b[39mNON_RETRYABLE_ERROR,\n\u001b[1;32m    210\u001b[0m         original_timeout,\n\u001b[1;32m    211\u001b[0m     )\n\u001b[0;32m--> 212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msource_exc\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    214\u001b[0m     on_error_fn(exc)\n",
      "File \u001b[0;32m~/Documents/GitHub/GCP-GenAI/.venv/lib/python3.11/site-packages/google/api_core/retry/retry_unary.py:144\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 144\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[1;32m    146\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
      "File \u001b[0;32m~/Documents/GitHub/GCP-GenAI/.venv/lib/python3.11/site-packages/google/api_core/grpc_helpers.py:78\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mInvalidArgument\u001b[0m: 400 User-specified resource ID must match the regular expression '[a-z0-9][a-z0-9-]{0,127}'"
     ]
    }
   ],
   "source": [
    "run_id = generate_uuid()\n",
    "eval_results = []\n",
    "\n",
    "\n",
    "for gemini_model in gemini_models:\n",
    "    experiment_run_name = f\"eval-prompt-engineering-{run_id}-prompt-{i}\"\n",
    "\n",
    "    eval_result = wc_si_eval_task.evaluate(\n",
    "        prompt_template=prompt_template,\n",
    "        experiment_run_name=experiment_run_name,\n",
    "        model=gemini_model,\n",
    "    )\n",
    "\n",
    "    eval_results.append(\n",
    "        (f\"Prompt #{i}\", eval_result.summary_metrics, eval_result.metrics_table)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for eval_result in eval_results:\n",
    "    display_eval_report(eval_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
